{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqXoEuz5E0Pc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Original ConvLSTM cell as proposed by Shi et al.\n",
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, \n",
        "    kernel_size, padding, activation, frame_size):\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()  \n",
        "\n",
        "        if activation == \"tanh\":\n",
        "            self.activation = torch.tanh \n",
        "        elif activation == \"relu\":\n",
        "            self.activation = torch.relu\n",
        "        \n",
        "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=in_channels + out_channels, \n",
        "            out_channels=4 * out_channels, \n",
        "            kernel_size=kernel_size, \n",
        "            padding=padding)           \n",
        "\n",
        "        # Initialize weights for Hadamard Products\n",
        "        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
        "        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
        "        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
        "\n",
        "    def forward(self, X, H_prev, C_prev):\n",
        "\n",
        "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "        conv_output = self.conv(torch.cat([X, H_prev], dim=1))\n",
        "\n",
        "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)\n",
        "\n",
        "        input_gate = torch.sigmoid(i_conv + self.W_ci * C_prev )\n",
        "        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_prev )\n",
        "\n",
        "        # Current Cell output\n",
        "        C = forget_gate*C_prev + input_gate * self.activation(C_conv)\n",
        "\n",
        "        output_gate = torch.sigmoid(o_conv + self.W_co * C )\n",
        "\n",
        "        # Current Hidden State\n",
        "        H = output_gate * self.activation(C)\n",
        "\n",
        "        return H, C"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EpTJh0RQWdkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fSnubZ2jkoBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0079dc5b-814e-49f0-bfaa-9ff06e31e915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QMgbBMbFBBa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, \n",
        "    kernel_size, padding, activation, frame_size):\n",
        "\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # We will unroll this over time steps\n",
        "        self.convLSTMcell = ConvLSTMCell(in_channels, out_channels, \n",
        "        kernel_size, padding, activation, frame_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)\n",
        "\n",
        "        # Get the dimensions\n",
        "        batch_size, _, seq_len, height, width = X.size()\n",
        "\n",
        "        # Initialize output\n",
        "        output = torch.zeros(batch_size, self.out_channels, seq_len, \n",
        "        height, width, device=device)\n",
        "        \n",
        "        # Initialize Hidden State\n",
        "        H = torch.zeros(batch_size, self.out_channels, \n",
        "        height, width, device=device)\n",
        "\n",
        "        # Initialize Cell Input\n",
        "        C = torch.zeros(batch_size,self.out_channels, \n",
        "        height, width, device=device)\n",
        "\n",
        "        # Unroll over time steps\n",
        "        for time_step in range(seq_len):\n",
        "\n",
        "            H, C = self.convLSTMcell(X[:,:,time_step], H, C)\n",
        "\n",
        "            output[:,:,time_step] = H\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjtzd82qFH1W"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, num_channels, num_kernels, kernel_size, padding, \n",
        "    activation, frame_size, num_layers):\n",
        "\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.sequential = nn.Sequential()\n",
        "\n",
        "        # Add First layer (Different in_channels than the rest)\n",
        "        self.sequential.add_module(\n",
        "            \"convlstm1\", ConvLSTM(\n",
        "                in_channels=num_channels, out_channels=num_kernels,\n",
        "                kernel_size=kernel_size, padding=padding, \n",
        "                activation=activation, frame_size=frame_size)\n",
        "        )\n",
        "\n",
        "        self.sequential.add_module(\n",
        "            \"batchnorm1\", nn.BatchNorm3d(num_features=num_kernels)\n",
        "        ) \n",
        "\n",
        "        # Add rest of the layers\n",
        "        for l in range(2, num_layers+1):\n",
        "\n",
        "            self.sequential.add_module(\n",
        "                f\"convlstm{l}\", ConvLSTM(\n",
        "                    in_channels=num_kernels, out_channels=num_kernels,\n",
        "                    kernel_size=kernel_size, padding=padding, \n",
        "                    activation=activation, frame_size=frame_size)\n",
        "                )\n",
        "                \n",
        "            self.sequential.add_module(\n",
        "                f\"batchnorm{l}\", nn.BatchNorm3d(num_features=num_kernels)\n",
        "                ) \n",
        "\n",
        "        # Add Convolutional Layer to predict output frame\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=num_kernels, out_channels=num_channels,\n",
        "            kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        # Forward propagation through all the layers\n",
        "        output = self.sequential(X)\n",
        "\n",
        "        # Return only the last output frame\n",
        "        output = self.conv(output[:,:,-1])\n",
        "        \n",
        "        return nn.Sigmoid()(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsa54bnKFQNq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(num_channels=1, num_kernels=64, \n",
        "kernel_size=(3, 3), padding=(1, 1), activation=\"relu\", \n",
        "frame_size=(64,64), num_layers=1).to(device)\n",
        "#model_state_dict = torch.load('drive/MyDrive/model.pth')\n",
        "#model.load_state_dict(model_state_dict)\n",
        "\n",
        "optim = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Binary Cross Entropy, target pixel values either 0 or 1\n",
        "criterion = nn.MSELoss (reduction=\"sum\")"
      ],
      "metadata": {
        "id": "YC394KqJWL7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib1AKfDhFR23"
      },
      "outputs": [],
      "source": [
        "# Load Data as Numpy Array\n",
        "from torch.utils.data import DataLoader\n",
        "MovingMNIST = np.load('drive/MyDrive/data_new.npy').astype(np.float32)\n",
        "\n",
        "train_data = MovingMNIST[0:18000] \n",
        "val_data = MovingMNIST[18000:19000]\n",
        "test_data = MovingMNIST[19000:20000]  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "\n",
        "    # Add channel dim, scale pixels between 0 and 1, send to GPU\n",
        "    batch = torch.tensor(batch).unsqueeze(1)                    \n",
        "    batch = batch.to(device)                     \n",
        "    # Randomly pick 10 frames as input, 11th frame is target\n",
        "    rand = np.random.randint(10,20)                     \n",
        "    return batch[:,:,rand-10:rand], batch[:,:,rand]     \n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data,shuffle=True, \n",
        "                         batch_size=16, collate_fn=collate)\n",
        "\n",
        "# Test Data Loader\n",
        "val_loader = DataLoader(val_data,shuffle=True, \n",
        "                         batch_size=16, collate_fn=collate)\n",
        "\n"
      ],
      "metadata": {
        "id": "C8QH8v5oCxRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfSCqWbRFVIA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "train_loss_l=[]\n",
        "val_loss_l=[]\n",
        "runnning_mae_train_l=[]\n",
        "runnning_mse_train_l=[]\n",
        "runnning_mae_val_l=[]\n",
        "runnning_mse_val_l=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U63OigIFdTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09faac28-f65b-4dee-f6fc-566d4b854a9b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Training Loss:206.71 Validation Loss:179.55 MAE_train: 470.3316 MSE_train:14.377335 MAE_val: 359.65225 MSE_val:13.39954\n",
            "\n",
            "Epoch:2 Training Loss:178.14 Validation Loss:174.04 MAE_train: 374.41104 MSE_train:13.346883 MAE_val: 371.00891 MSE_val:13.19234\n",
            "\n",
            "Epoch:3 Training Loss:173.53 Validation Loss:167.83 MAE_train: 363.41245 MSE_train:13.173269 MAE_val: 356.43884 MSE_val:12.954769\n",
            "\n",
            "Epoch:4 Training Loss:171.41 Validation Loss:169.76 MAE_train: 357.70255 MSE_train:13.092456 MAE_val: 340.77963 MSE_val:13.029192\n",
            "\n",
            "Epoch:5 Training Loss:168.36 Validation Loss:170.07 MAE_train: 349.43109 MSE_train:12.975414 MAE_val: 346.92786 MSE_val:13.040998\n",
            "\n",
            "Epoch:6 Training Loss:165.21 Validation Loss:166.78 MAE_train: 341.85593 MSE_train:12.853466 MAE_val: 330.64008 MSE_val:12.914156\n",
            "\n",
            "Epoch:7 Training Loss:165.82 Validation Loss:166.63 MAE_train: 342.05682 MSE_train:12.877195 MAE_val: 349.74814 MSE_val:12.90862\n",
            "\n",
            "Epoch:8 Training Loss:166.40 Validation Loss:163.61 MAE_train: 342.27063 MSE_train:12.899535 MAE_val: 337.63437 MSE_val:12.790843\n",
            "\n",
            "Epoch:9 Training Loss:164.28 Validation Loss:163.75 MAE_train: 337.45236 MSE_train:12.817157 MAE_val: 339.41891 MSE_val:12.796464\n",
            "\n",
            "Epoch:10 Training Loss:162.88 Validation Loss:163.52 MAE_train: 334.2413 MSE_train:12.762336 MAE_val: 339.31772 MSE_val:12.787342\n",
            "\n",
            "Epoch:11 Training Loss:162.01 Validation Loss:167.65 MAE_train: 332.38077 MSE_train:12.728469 MAE_val: 314.26733 MSE_val:12.94811\n",
            "\n",
            "Epoch:12 Training Loss:163.35 Validation Loss:159.03 MAE_train: 334.66275 MSE_train:12.780962 MAE_val: 316.95029 MSE_val:12.610753\n",
            "\n",
            "Epoch:13 Training Loss:162.36 Validation Loss:155.83 MAE_train: 332.42004 MSE_train:12.742189 MAE_val: 324.13068 MSE_val:12.483189\n",
            "\n",
            "Epoch:14 Training Loss:162.88 Validation Loss:161.99 MAE_train: 333.56113 MSE_train:12.762448 MAE_val: 331.89551 MSE_val:12.727486\n",
            "\n",
            "Epoch:15 Training Loss:160.71 Validation Loss:159.94 MAE_train: 329.11856 MSE_train:12.677116 MAE_val: 321.38138 MSE_val:12.646847\n",
            "\n",
            "Epoch:16 Training Loss:160.36 Validation Loss:157.67 MAE_train: 328.02963 MSE_train:12.663194 MAE_val: 328.87393 MSE_val:12.556529\n",
            "\n",
            "Epoch:17 Training Loss:159.56 Validation Loss:154.59 MAE_train: 327.04132 MSE_train:12.63169 MAE_val: 326.88004 MSE_val:12.433339\n",
            "\n",
            "Epoch:18 Training Loss:160.73 Validation Loss:155.17 MAE_train: 329.19363 MSE_train:12.677808 MAE_val: 328.10468 MSE_val:12.456606\n",
            "\n",
            "Epoch:19 Training Loss:159.79 Validation Loss:155.72 MAE_train: 327.16693 MSE_train:12.640622 MAE_val: 328.2428 MSE_val:12.478781\n",
            "\n",
            "Epoch:20 Training Loss:160.20 Validation Loss:162.42 MAE_train: 327.95767 MSE_train:12.656949 MAE_val: 326.4881 MSE_val:12.744464\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "import math\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    runnning_mae_train=0\n",
        "    runnning_mse_train=0\n",
        "    train_loss = 0                                                 \n",
        "    model.train()                                                  \n",
        "    for batch_num, (input, target) in enumerate(train_loader, 1):  \n",
        "        output = model(input)                                  \n",
        "        loss = criterion(output.flatten(), target.flatten())       \n",
        "        loss.backward()                                            \n",
        "        optim.step()                                               \n",
        "        optim.zero_grad()                                           \n",
        "        train_loss += loss.item() \n",
        "        error = torch.abs(output.flatten() - target.flatten()).sum().data\n",
        "        squared_error = ((output.flatten() - target.flatten())*(output.flatten() - target.flatten())).sum().data\n",
        "        runnning_mae_train += error\n",
        "        runnning_mse_train += squared_error\n",
        "      \n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    runnning_mae_train /= len(train_loader.dataset) \n",
        "    runnning_mse_train = math.sqrt(runnning_mse_train / len(train_loader.dataset))                     \n",
        "    val_loss = 0  \n",
        "    runnning_mae_val=0\n",
        "    runnning_mse_val=0                                               \n",
        "    model.eval()                                                   \n",
        "    with torch.no_grad():                                          \n",
        "        for input, target in val_loader:                          \n",
        "            output = model(input)                                \n",
        "            loss = criterion(output.flatten(), target.flatten())   \n",
        "            val_loss += loss.item()\n",
        "            error = torch.abs(output.flatten() - target.flatten()).sum().data\n",
        "            squared_error = ((output.flatten() - target.flatten())*(output.flatten() - target.flatten())).sum().data\n",
        "            runnning_mae_val += error\n",
        "            runnning_mse_val += squared_error                              \n",
        "    val_loss /= len(val_loader.dataset)  \n",
        "    runnning_mae_val /= len(val_loader.dataset) \n",
        "    runnning_mse_val = math.sqrt(runnning_mse_val / len(val_loader.dataset) )                          \n",
        "    torch.save(model.state_dict(),f'drive/MyDrive/model_{epoch}.pth')\n",
        "    print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f} MAE_train: {:.8} MSE_train:{:.8} MAE_val: {:.8} MSE_val:{:.8}\\n\".format(\n",
        "        epoch, train_loss, val_loss,runnning_mae_train,runnning_mse_train,runnning_mae_val,runnning_mse_val))\n",
        "    train_loss_l.append(train_loss)\n",
        "    val_loss_l.append(val_loss)\n",
        "    runnning_mae_train_l.append(runnning_mae_train)\n",
        "    runnning_mse_train_l.append(runnning_mse_train)\n",
        "    runnning_mae_val_l.append(runnning_mae_val)\n",
        "    runnning_mse_val_l.append(runnning_mse_val)\n",
        "    np.save(\"drive/MyDrive/train_loss_l.npy\",np.array(train_loss_l))\n",
        "    np.save(\"drive/MyDrive/val_loss_l.npy\",np.array(val_loss_l))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collate_test(batch):\n",
        "\n",
        "    # Last 10 frames are target\n",
        "    target = np.array(batch)[:,10:]                     \n",
        "    \n",
        "    # Add channel dim, scale pixels between 0 and 1, send to GPU\n",
        "    batch = torch.tensor(batch).unsqueeze(1)                                    \n",
        "    batch = batch.to(device)                          \n",
        "    return batch, target\n",
        "\n",
        "# Test Data Loader\n",
        "test_loader = DataLoader(test_data,shuffle=True, \n",
        "                         batch_size=1000, collate_fn=collate_test)\n",
        "\n",
        "# Get a batch\n",
        "batch, target = next(iter(test_loader))\n",
        "\n",
        "# Initialize output sequence\n",
        "output = np.zeros(target.shape, dtype=np.uint8)\n",
        "\n",
        "# Loop over timesteps\n",
        "for timestep in range(target.shape[1]):\n",
        "  input = batch[:,:,timestep:timestep+10]   \n",
        "  output[:,timestep]=(model(input).squeeze(1).cpu()>0.5)*255.0"
      ],
      "metadata": {
        "id": "ckO8ImseRZVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "73535a5f-eb97-4153-bea5-018ff6235726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3a53fb2a1282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Test Data Loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m test_loader = DataLoader(test_data,shuffle=True, \n\u001b[0m\u001b[1;32m     13\u001b[0m                          batch_size=1000, collate_fn=collate_test)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5MToUAUZJagm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tgt, out in zip(target, output):       # Loop over samples\n",
        "    \n",
        "    # Write target video as gif\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif, tgt, \"GIF\", fps = 1)    \n",
        "        target_gif = gif.getvalue()\n",
        "\n",
        "    # Write output video as gif\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif, out, \"GIF\", fps = 1)    \n",
        "        output_gif = gif.getvalue()\n",
        "\n",
        "    display(HBox([widgets.Image(value=target_gif), \n",
        "                  widgets.Image(value=output_gif)]))"
      ],
      "metadata": {
        "id": "85XITG54oeeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of videoframe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}